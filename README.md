# DeepVariant-Slurm

*\[Disclaimer: The pipelines are not 100% tested and/or guaranteed to be complete. Some DeepVariant parameters are hard-coded. All `sbatch` parameters are hard-coded as header comments. This is meant to be more of a template than a complete program.\]*

First of all, you should have a Singularity image of your favorite version of DeepVariant in order to run these pipelines. You can see in the test script that I'm referencing an image called `deepvariant-0.9.0.simg`. Also, I'm using test data from a folder called "quickstart-testdata". Both are provided by Google and can be found here: https://console.cloud.google.com/storage/browser/deepvariant. You might find some other useful stuff in there as well.

Regarding the singularity image, I suggest you find the docker image that you want to use and convert it to a singularity image using docker2singularity. You can see a sample script in my DeepVariant repo that I forked from Google. After that, just transfer the singularity image to your HPC account and run it or execute any command in it as you wish.

Once you have everything ready, you can run the tests simply by just running the command `./run-deepvariant-calling-test` or any other script with the prefix `run`. You can also directly run the pipelines with `./deepvariant-calling --arg1 value1 --arg2 value2` for the calling pipeline, or `./deepvariant-training --args values --randomflag` for the training pipeline, for example. Some arguments are required, so make sure to inspect the scripts first, and make sure the scripts are executable using `chmod u+x <script>`, add `sudo` if needed.

The structure of the pipelines can be seen in those two files: `deepvariant-calling.sh` and `deepvariant-training.sh`. These pipelines preprocess the inputs and then pass them to some slurm job scripts. Most of the inputs are specific to the DeepVariant commands, so you can refer to the files prefixed with `dv-help` (I just put them all in the help folder `help/`). All of the job scripts can be found in the folder `scripts/` with the prefix `dv-slurm`. The scripts prefixed with `dv-local` mimic the pipelines locally (without submitting any jobs to slurm). So, for example, `deepvariant-calling` runs 3 jobs sequentially: `make-examples`, `call-variants`, and then `postprocess-variants`. Each of these jobs have different requirements. For example, the job `call-variants` benefits a lot from a GPU node, whereas the job `make-examples` is time-consuming and benefits more from a large number of CPUs. The job scripts usually consist from a single command performed using the DeepVariant singularity image that you specify with `--simg`. The `deepvariant-training` pipeline is a bit more involved, but it follows the same structure. In any case, I tried to write the code in a readable manner (where it matters, at least), so it should be pretty understandable with a little bit of effort.
